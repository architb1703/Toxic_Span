{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Finalprediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eb30fae1db3c4d7981f314efaed43744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_64587bf0800945c1aef9ab70facf92ca",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7e63d5a523d14e9db305c967af8bcdee",
              "IPY_MODEL_07c98439f7c241f98d6d4170f5b34795"
            ]
          }
        },
        "64587bf0800945c1aef9ab70facf92ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e63d5a523d14e9db305c967af8bcdee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_044e6439d72d458f9a097a4e166b3110",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b24a8208cf0e426eb2005f1dc3f9bb59"
          }
        },
        "07c98439f7c241f98d6d4170f5b34795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2c939107cb0b428f885fa8a47fdebabc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:15&lt;00:00, 13.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9255aa4e9ee4f5092aa37d4f3427a22"
          }
        },
        "044e6439d72d458f9a097a4e166b3110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b24a8208cf0e426eb2005f1dc3f9bb59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c939107cb0b428f885fa8a47fdebabc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9255aa4e9ee4f5092aa37d4f3427a22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/architb1703/Toxic_Span/blob/Abhay/Finalprediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HFdqstxfhdQ"
      },
      "source": [
        "# First do the preprocessing on the test dataset......\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PptsRx2mZZQ9",
        "outputId": "50392fb3-69e2-4bff-ea38-1bd871f9cc39"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf09MtzB2XHG"
      },
      "source": [
        "###PATHS\n",
        "\n",
        "test_path ='drive/MyDrive/Final/test.csv'  #will be used to open test.csv\n",
        "\n",
        "model_path='drive/MyDrive/Final/semi_sup-6.pt'  # will be used to load model\n",
        "\n",
        "save_path = 'drive/MyDrive/Final/predicted1.csv' # predicted.csv will store the predicted tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NNlEyqDpItD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b3bdb5f-57cd-497d-b846-02a835ea7494"
      },
      "source": [
        "pip install contractions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/ce/ad/d1c685967945a04f8596128b15a1ab56c51488f53312e953341af6ff22d1/contractions-0.0.43-py2.py3-none-any.whl\n",
            "Collecting textsearch\n",
            "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
            "Collecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 8.4MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 9.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81700 sha256=53963fa8828eb478e469927c095ce4cc61247c49e4c61c840754c491a7b75458\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: Unidecode, pyahocorasick, textsearch, contractions\n",
            "Successfully installed Unidecode-1.1.1 contractions-0.0.43 pyahocorasick-1.4.0 textsearch-0.0.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_tBb4AvAhVG"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvhpwznOh8ab"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew-OORqDAhVK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6d13e298-7837-4a63-d3d1-3ba97a75e925"
      },
      "source": [
        "# import data\n",
        "from ast import literal_eval\n",
        "pred = pd.read_csv(test_path)\n",
        "pred.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I completely agree, Sylvia is a moron.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If Kitty is giving them $17,000 a year to sit ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If someone does not know that drug use can kee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Maybe we can get those people to hand feed the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the work of soros' whores</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0             I completely agree, Sylvia is a moron.\n",
              "1  If Kitty is giving them $17,000 a year to sit ...\n",
              "2  If someone does not know that drug use can kee...\n",
              "3  Maybe we can get those people to hand feed the...\n",
              "4                          the work of soros' whores"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn-ecbXYAhVM"
      },
      "source": [
        "# corpus = dup of \"train\"\n",
        "corpus = pred.copy()\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "felL0iqIAhVP"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85o2H1dcAhVR"
      },
      "source": [
        "# stats of words and chars\n",
        "length_of_words = corpus['text'].apply(lambda x: len(x.split()))\n",
        "length_of_text = corpus['text'].apply(lambda x: len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA_dH5rGAhVT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9pYaMKnAhVV"
      },
      "source": [
        "\n",
        "from nltk.tokenize import TreebankWordTokenizer as twt\n",
        "\n",
        "def tokens(string):\n",
        "    tokens = twt().tokenize(string)\n",
        "    return tokens \n",
        "\n",
        "def spans_of_tokens(string):\n",
        "    list_of_spans = list(twt().span_tokenize(string))\n",
        "    return list_of_spans\n",
        "\n",
        "corpus[\"tokenize\"] = corpus[\"text\"].apply(lambda x: tokens(x.replace('\"', \"'\")))\n",
        "corpus[\"spans_of_tokens\"] = corpus[\"text\"].apply(lambda x: spans_of_tokens(x.replace('\"', \"'\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "xl-5EOLQmOS7",
        "outputId": "e46f3382-76d0-47c1-a1b7-6c3894a49234"
      },
      "source": [
        "corpus.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tokenize</th>\n",
              "      <th>spans_of_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I completely agree, Sylvia is a moron.</td>\n",
              "      <td>[I, completely, agree, ,, Sylvia, is, a, moron...</td>\n",
              "      <td>[(0, 1), (2, 12), (13, 18), (18, 19), (20, 26)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If Kitty is giving them $17,000 a year to sit ...</td>\n",
              "      <td>[If, Kitty, is, giving, them, $, 17,000, a, ye...</td>\n",
              "      <td>[(0, 2), (3, 8), (9, 11), (12, 18), (19, 23), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If someone does not know that drug use can kee...</td>\n",
              "      <td>[If, someone, does, not, know, that, drug, use...</td>\n",
              "      <td>[(0, 2), (3, 10), (11, 15), (16, 19), (20, 24)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Maybe we can get those people to hand feed the...</td>\n",
              "      <td>[Maybe, we, can, get, those, people, to, hand,...</td>\n",
              "      <td>[(0, 5), (6, 8), (9, 12), (13, 16), (17, 22), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the work of soros' whores</td>\n",
              "      <td>[the, work, of, soros, ', whores]</td>\n",
              "      <td>[(0, 3), (4, 8), (9, 11), (12, 17), (17, 18), ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                    spans_of_tokens\n",
              "0             I completely agree, Sylvia is a moron.  ...  [(0, 1), (2, 12), (13, 18), (18, 19), (20, 26)...\n",
              "1  If Kitty is giving them $17,000 a year to sit ...  ...  [(0, 2), (3, 8), (9, 11), (12, 18), (19, 23), ...\n",
              "2  If someone does not know that drug use can kee...  ...  [(0, 2), (3, 10), (11, 15), (16, 19), (20, 24)...\n",
              "3  Maybe we can get those people to hand feed the...  ...  [(0, 5), (6, 8), (9, 12), (13, 16), (17, 22), ...\n",
              "4                          the work of soros' whores  ...  [(0, 3), (4, 8), (9, 11), (12, 17), (17, 18), ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INLUvdbPAhVZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYiUPNYVAhVb"
      },
      "source": [
        "# zipped together -> token, their spans\n",
        "temp = []\n",
        "for i in range(len(corpus)):\n",
        "    temp.append(list(zip(corpus.tokenize[i], corpus.spans_of_tokens[i])))\n",
        "\n",
        "for i in range(len(temp)):    \n",
        "    temp[i] = [list(ele) for ele in temp[i]]  \n",
        "\n",
        "corpus[\"zipped\"] = temp\n",
        "# del temp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3qaCeDPuvAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c3f670-76e7-4c46-b36e-c7eb9f1e5987"
      },
      "source": [
        "corpus.zipped[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['I', (0, 1)],\n",
              " ['completely', (2, 12)],\n",
              " ['agree', (13, 18)],\n",
              " [',', (18, 19)],\n",
              " ['Sylvia', (20, 26)],\n",
              " ['is', (27, 29)],\n",
              " ['a', (30, 31)],\n",
              " ['moron', (32, 37)],\n",
              " ['.', (37, 38)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2pMVdNvAhVd"
      },
      "source": [
        "#################### cleaning functions ####################\n",
        "# emoji removing function\n",
        "def deEmojify(text):\n",
        "    regrex_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "    return regrex_pattern.sub(r'',text)\n",
        "\n",
        "#puntuation remover\n",
        "# from string import punctuation\n",
        "# def strip_punctuation(text):\n",
        "#     return ''.join(c for c in text if c not in punctuation)\n",
        "\n",
        "#convert accented text\n",
        "import unicodedata\n",
        "def convert_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "\n",
        "#expand contraction\n",
        "import contractions\n",
        "import re \n",
        "\n",
        "# function to expand contractions\n",
        "def expand_contractions(text):\n",
        "    return(contractions.fix(text))\n",
        "# function to remove digits\n",
        "def remove_nums(text):\n",
        "    return re.sub('[0-9]+', '', text)\n",
        "\n",
        "# remove special chars\n",
        "def remove_spe_chars(text):\n",
        "    return re.sub('\\.+', '.', text)\n",
        "#################### cleaning functions ####################    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZjCBK7-AhVf"
      },
      "source": [
        "#cleaning tokens (in zipped)\n",
        "def clean_string(string):\n",
        "    # string = string.lower()#lowercasing\n",
        "    string = expand_contractions(string) #expand contraction\n",
        "    string = remove_nums(string)#remove digits\n",
        "    #numbers into words(could be done if required)# not require though\n",
        "    string = convert_accented_chars(string)#convert accented\n",
        "    string = deEmojify(string)#remove emoji\n",
        "    string = remove_spe_chars(string)#combine all multiple full stops occurring together\n",
        "    \n",
        "    return string\n",
        "\n",
        "def cleaning(iterable):\n",
        "    for i in range(len(iterable)):\n",
        "        iterable[i][0] = clean_string(iterable[i][0])    \n",
        "    \n",
        "    return iterable\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKt9m9NkAhVh"
      },
      "source": [
        "#remove empty tokens (in zipped)\n",
        "def remove_empty(iterable):\n",
        "    iterable = list(filter(lambda x: x[0] != '', iterable))\n",
        "    return iterable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aosYsVfAhVk"
      },
      "source": [
        "# clean\n",
        "corpus.zipped = corpus.zipped.apply(lambda x: cleaning(x))\n",
        "# remove nulls\n",
        "corpus.zipped = corpus.zipped.apply(lambda x: remove_empty(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJnf9ZncAhVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed17bb51-666d-4563-8ee7-67be16719986"
      },
      "source": [
        "corpus.zipped[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['I', (0, 1)],\n",
              " ['completely', (2, 12)],\n",
              " ['agree', (13, 18)],\n",
              " [',', (18, 19)],\n",
              " ['Sylvia', (20, 26)],\n",
              " ['is', (27, 29)],\n",
              " ['a', (30, 31)],\n",
              " ['moron', (32, 37)],\n",
              " ['.', (37, 38)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER2DJwZ8AhVq"
      },
      "source": [
        "\n",
        "\n",
        "def redeem_spans(lis):\n",
        "    arr = []\n",
        "    for item in lis:\n",
        "        arr.append(item[1])\n",
        "    return arr\n",
        "\n",
        "def reddem_token(lis):\n",
        "    arr = []\n",
        "    for item in lis:\n",
        "        arr.append(item[0])\n",
        "    return arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_WmjchbAhVs"
      },
      "source": [
        "\n",
        "corpus['span_final'] = corpus.zipped.apply(lambda x : redeem_spans(x))\n",
        "\n",
        "corpus['token_final'] = corpus.zipped.apply(lambda x : reddem_token(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm49b6mrtlM7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "6b0566f5-217e-4820-85f8-3e73624ab75b"
      },
      "source": [
        "corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tokenize</th>\n",
              "      <th>spans_of_tokens</th>\n",
              "      <th>zipped</th>\n",
              "      <th>span_final</th>\n",
              "      <th>token_final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I completely agree, Sylvia is a moron.</td>\n",
              "      <td>[I, completely, agree, ,, Sylvia, is, a, moron...</td>\n",
              "      <td>[(0, 1), (2, 12), (13, 18), (18, 19), (20, 26)...</td>\n",
              "      <td>[[I, (0, 1)], [completely, (2, 12)], [agree, (...</td>\n",
              "      <td>[(0, 1), (2, 12), (13, 18), (18, 19), (20, 26)...</td>\n",
              "      <td>[I, completely, agree, ,, Sylvia, is, a, moron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If Kitty is giving them $17,000 a year to sit ...</td>\n",
              "      <td>[If, Kitty, is, giving, them, $, 17,000, a, ye...</td>\n",
              "      <td>[(0, 2), (3, 8), (9, 11), (12, 18), (19, 23), ...</td>\n",
              "      <td>[[If, (0, 2)], [Kitty, (3, 8)], [is, (9, 11)],...</td>\n",
              "      <td>[(0, 2), (3, 8), (9, 11), (12, 18), (19, 23), ...</td>\n",
              "      <td>[If, Kitty, is, giving, them, $, ,, a, year, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If someone does not know that drug use can kee...</td>\n",
              "      <td>[If, someone, does, not, know, that, drug, use...</td>\n",
              "      <td>[(0, 2), (3, 10), (11, 15), (16, 19), (20, 24)...</td>\n",
              "      <td>[[If, (0, 2)], [someone, (3, 10)], [does, (11,...</td>\n",
              "      <td>[(0, 2), (3, 10), (11, 15), (16, 19), (20, 24)...</td>\n",
              "      <td>[If, someone, does, not, know, that, drug, use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Maybe we can get those people to hand feed the...</td>\n",
              "      <td>[Maybe, we, can, get, those, people, to, hand,...</td>\n",
              "      <td>[(0, 5), (6, 8), (9, 12), (13, 16), (17, 22), ...</td>\n",
              "      <td>[[Maybe, (0, 5)], [we, (6, 8)], [can, (9, 12)]...</td>\n",
              "      <td>[(0, 5), (6, 8), (9, 12), (13, 16), (17, 22), ...</td>\n",
              "      <td>[Maybe, we, can, get, those, people, to, hand,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the work of soros' whores</td>\n",
              "      <td>[the, work, of, soros, ', whores]</td>\n",
              "      <td>[(0, 3), (4, 8), (9, 11), (12, 17), (17, 18), ...</td>\n",
              "      <td>[[the, (0, 3)], [work, (4, 8)], [of, (9, 11)],...</td>\n",
              "      <td>[(0, 3), (4, 8), (9, 11), (12, 17), (17, 18), ...</td>\n",
              "      <td>[the, work, of, soros, ', whores]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>789</th>\n",
              "      <td>True.....for once UR right.\\nBut the thing is,...</td>\n",
              "      <td>[True, ..., ..for, once, UR, right., But, the,...</td>\n",
              "      <td>[(0, 4), (4, 7), (7, 12), (13, 17), (18, 20), ...</td>\n",
              "      <td>[[True, (0, 4)], [., (4, 7)], [.for, (7, 12)],...</td>\n",
              "      <td>[(0, 4), (4, 7), (7, 12), (13, 17), (18, 20), ...</td>\n",
              "      <td>[True, ., .for, once, UR, right., But, the, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>790</th>\n",
              "      <td>Naw. The best way to remove the terrorists' po...</td>\n",
              "      <td>[Naw., The, best, way, to, remove, the, terror...</td>\n",
              "      <td>[(0, 4), (5, 8), (9, 13), (14, 17), (18, 20), ...</td>\n",
              "      <td>[[Naw., (0, 4)], [The, (5, 8)], [best, (9, 13)...</td>\n",
              "      <td>[(0, 4), (5, 8), (9, 13), (14, 17), (18, 20), ...</td>\n",
              "      <td>[Naw., The, best, way, to, remove, the, terror...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>791</th>\n",
              "      <td>imagine if this dumb witch every cared about m...</td>\n",
              "      <td>[imagine, if, this, dumb, witch, every, cared,...</td>\n",
              "      <td>[(0, 7), (8, 10), (11, 15), (16, 20), (21, 26)...</td>\n",
              "      <td>[[imagine, (0, 7)], [if, (8, 10)], [this, (11,...</td>\n",
              "      <td>[(0, 7), (8, 10), (11, 15), (16, 20), (21, 26)...</td>\n",
              "      <td>[imagine, if, this, dumb, witch, every, cared,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>792</th>\n",
              "      <td>Why thank you for your vey civil remark.  I ag...</td>\n",
              "      <td>[Why, thank, you, for, your, vey, civil, remar...</td>\n",
              "      <td>[(0, 3), (4, 9), (10, 13), (14, 17), (18, 22),...</td>\n",
              "      <td>[[Why, (0, 3)], [thank, (4, 9)], [you, (10, 13...</td>\n",
              "      <td>[(0, 3), (4, 9), (10, 13), (14, 17), (18, 22),...</td>\n",
              "      <td>[Why, thank, you, for, your, vey, civil, remar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>793</th>\n",
              "      <td>I hope he does, the bomb the crap out of Bruss...</td>\n",
              "      <td>[I, hope, he, does, ,, the, bomb, the, crap, o...</td>\n",
              "      <td>[(0, 1), (2, 6), (7, 9), (10, 14), (14, 15), (...</td>\n",
              "      <td>[[I, (0, 1)], [hope, (2, 6)], [he, (7, 9)], [d...</td>\n",
              "      <td>[(0, 1), (2, 6), (7, 9), (10, 14), (14, 15), (...</td>\n",
              "      <td>[I, hope, he, does, ,, the, bomb, the, crap, o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>794 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  ...                                        token_final\n",
              "0               I completely agree, Sylvia is a moron.  ...  [I, completely, agree, ,, Sylvia, is, a, moron...\n",
              "1    If Kitty is giving them $17,000 a year to sit ...  ...  [If, Kitty, is, giving, them, $, ,, a, year, t...\n",
              "2    If someone does not know that drug use can kee...  ...  [If, someone, does, not, know, that, drug, use...\n",
              "3    Maybe we can get those people to hand feed the...  ...  [Maybe, we, can, get, those, people, to, hand,...\n",
              "4                            the work of soros' whores  ...                  [the, work, of, soros, ', whores]\n",
              "..                                                 ...  ...                                                ...\n",
              "789  True.....for once UR right.\\nBut the thing is,...  ...  [True, ., .for, once, UR, right., But, the, th...\n",
              "790  Naw. The best way to remove the terrorists' po...  ...  [Naw., The, best, way, to, remove, the, terror...\n",
              "791  imagine if this dumb witch every cared about m...  ...  [imagine, if, this, dumb, witch, every, cared,...\n",
              "792  Why thank you for your vey civil remark.  I ag...  ...  [Why, thank, you, for, your, vey, civil, remar...\n",
              "793  I hope he does, the bomb the crap out of Bruss...  ...  [I, hope, he, does, ,, the, bomb, the, crap, o...\n",
              "\n",
              "[794 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRlcwFzqAhVu"
      },
      "source": [
        "final_data = corpus[['text', 'span_final', 'token_final']].copy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u9c1xSCAhVx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcG7ckueAhVz"
      },
      "source": [
        "use_tokens=final_data['token_final'].tolist()\n",
        "use_spans=final_data['span_final'].tolist()\n",
        "use_text=final_data['text'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei5OBtqT33Q_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVN5xanq35fm"
      },
      "source": [
        "# Load the model and predict\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NygFtcIUyuCK",
        "outputId": "cde64cb5-8702-428f-fce6-e633a914d8cf"
      },
      "source": [
        "#model1\n",
        "\n",
        "!pip install transformers==2.6.0\n",
        "!pip install seqeval\n",
        "!pip install urllib3 --upgrade\n",
        "\n",
        "\n",
        "#Importing libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torchtext import data\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertConfig, BertForTokenClassification, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from seqeval.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(12)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a0/32e3a4501ef480f7ea01aac329a716132f32f7911ef1c2fac228acc57ca7/transformers-2.6.0-py3-none-any.whl (540kB)\n",
            "\u001b[K     |████████████████████████████████| 542kB 8.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 14.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (2.23.0)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/cd/513fff674c22507caf5a983ac1aacf87fc207535ada17d720199b51b6cc3/boto3-1.16.36-py2.py3-none-any.whl (130kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 34.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 23.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (1.18.5)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 44.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.6.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.6.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.6.0) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.6.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.6.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.6.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.6.0) (1.24.3)\n",
            "Collecting botocore<1.20.0,>=1.19.36\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/27/f8757c8d3d11a2332677e2be978f2a524ab13d07d3766e2fff18693e6f3d/botocore-1.19.36-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 34.4MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.36->boto3->transformers==2.6.0) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=200cab31eff90d44082d2c028a3f33f27dbfb1ba584db2af5beaa125a9c783cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "\u001b[31mERROR: botocore 1.19.36 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sacremoses, jmespath, botocore, s3transfer, boto3, sentencepiece, tokenizers, transformers\n",
            "Successfully installed boto3-1.16.36 botocore-1.19.36 jmespath-0.10.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.5.2 transformers-2.6.0\n",
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=78b26afc49433ce992ec4bdcff29e32f59e8dcbd940aa610b1f165db88bcc6f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "Collecting urllib3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/71/45d36a8df68f3ebb098d6861b2c017f3d094538c0fb98fa61d4dc43e69b9/urllib3-1.26.2-py2.py3-none-any.whl (136kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 9.1MB/s \n",
            "\u001b[31mERROR: requests 2.23.0 has requirement urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed urllib3-1.26.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.2) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai7qv26gHxoG"
      },
      "source": [
        "#Class to take in tokenizer and model along with input data and calculate the span average f1 score\n",
        "class SpanAvgF1():\n",
        "  def __init__(self, model, tokenizer, X, spans, maxlen=500):\n",
        "    self.model = model\n",
        "    self.model.cuda()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.maxlen = maxlen\n",
        "    self.X = X\n",
        "    self.spans = spans\n",
        "    \n",
        "    self.prepare_data()\n",
        "\n",
        "    self.X = torch.tensor(self.X)\n",
        "    self.attention_mask = torch.tensor(self.attention_mask)\n",
        "\n",
        "    data = TensorDataset(self.X, self.attention_mask)\n",
        "    self.dataloader = DataLoader(data, batch_size=16, shuffle=False)\n",
        "  \n",
        "  def tokenize_data(self, x, s):\n",
        "    sentence = []\n",
        "    spans = []\n",
        "    for i in range(len(x)):\n",
        "      word = x[i]\n",
        "      # label = y[i]\n",
        "      tokenized_word = self.tokenizer.tokenize(word)\n",
        "      sentence.extend(tokenized_word)\n",
        "      curr = s[i][0]\n",
        "      spans.append([curr, curr+len(tokenized_word[0])])\n",
        "      curr += len(tokenized_word[0])\n",
        "      for j in range(len(tokenized_word)-1):\n",
        "        spans.append([curr, curr+len(tokenized_word[j+1])-2])\n",
        "        curr += len(tokenized_word[j+1])-2\n",
        "      spans[-1][-1] = s[i][1]\n",
        "\n",
        "    return(sentence, spans)\n",
        "\n",
        "  def get_attention_mask(self, x):\n",
        "    return([[(i!=0) for i in text] for text in x])\n",
        "\n",
        "  def prepare_data(self):\n",
        "    for i in range(len(self.X)):\n",
        "      self.X[i], self.spans[i] = self.tokenize_data(self.X[i], self.spans[i])\n",
        "    self.X = pad_sequences([tokenizer.encode(text) for text in self.X], maxlen = self.maxlen, dtype='long', value=0.0, truncating='post', padding = 'post')\n",
        "    # self.y = pad_sequences(self.y, maxlen=self.maxlen, value=2, dtype='long', truncating='post', padding='post')\n",
        "    self.attention_mask = self.get_attention_mask(self.X)\n",
        "  \n",
        "  def get_text_lengths(self, masks):\n",
        "    lengths = []\n",
        "    for mask in masks:\n",
        "      lengths.append(torch.sum(mask).item())\n",
        "    return(lengths)\n",
        "\n",
        "  def evaluate(self):\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in self.dataloader:\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      b_input_id, b_input_mask = batch\n",
        "      # b_input_id, b_input_mask, b_labels = batch\n",
        "      self.model.eval()\n",
        "\n",
        "      with torch.no_grad():\n",
        "          outputs = self.model(b_input_id, token_type_ids=None, attention_mask=b_input_mask)\n",
        "      logits = outputs[0].detach().cpu().numpy()\n",
        "      predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "      true_labels.extend(b_input_mask)\n",
        "    \n",
        "    self.pred_tags = [[p_i for p_i, l_i in zip(p, l) if l_i != 0][1:-1] for p, l in zip(predictions, true_labels)]\n",
        "    # else:\n",
        "    #   self.pred_tags = predictions\n",
        "    # self.pred_tags = predictions\n",
        "    return self.pred_tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39SXP1rdXCS3"
      },
      "source": [
        "X = use_tokens.copy()\n",
        "spans = use_spans.copy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYVZx2Gg-itJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzPPIIVRA3gg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x-Ym2k1XEII",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "eb30fae1db3c4d7981f314efaed43744",
            "64587bf0800945c1aef9ab70facf92ca",
            "7e63d5a523d14e9db305c967af8bcdee",
            "07c98439f7c241f98d6d4170f5b34795",
            "044e6439d72d458f9a097a4e166b3110",
            "b24a8208cf0e426eb2005f1dc3f9bb59",
            "2c939107cb0b428f885fa8a47fdebabc",
            "a9255aa4e9ee4f5092aa37d4f3427a22"
          ]
        },
        "outputId": "c8ffc2b1-cb5e-4a75-b8fb-f16a1dfef9b8"
      },
      "source": [
        "\n",
        "modelorg = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "model= modelorg\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb30fae1db3c4d7981f314efaed43744",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-2ILU5iXVMC"
      },
      "source": [
        "model=modelorg\n",
        "metric = SpanAvgF1(model, tokenizer, X, spans)\n",
        "out=metric.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00zcLxmqT9Px"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M31cFXVaU1f5"
      },
      "source": [
        "predicted_spans=[]\n",
        "for i in range(len(spans)):\n",
        "  s = [0 for k in range(len(use_text[i]))]\n",
        "  prev = 0\n",
        "  for j in range(len(spans[i])):\n",
        "    for k in range(spans[i][j][0], spans[i][j][1]):\n",
        "      s[k] = out[i][j]\n",
        "    if(prev==1 and out[i][j]==1):\n",
        "      for l in range(spans[i][j-1][1], spans[i][j][0]):\n",
        "        s[l] = 1\n",
        "    prev = out[i][j]\n",
        "  predicted_spans.append(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11vIQb94ffXC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtNq_q5OlU57"
      },
      "source": [
        "final_offsets=[]\n",
        "for x in predicted_spans:\n",
        "  lis=[]\n",
        "  for i in range(len(x)):\n",
        "    if x[i]==1:\n",
        "      lis.append(i)\n",
        "  final_offsets.append(lis)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plmxbyxAplVv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkVPPbBbsHY8"
      },
      "source": [
        "\n",
        "data = {'spans':final_offsets,'text':use_text}\n",
        " \n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df.to_csv(save_path,index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkXewEVFGp0X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8AaScIDGrRj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}